{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from sklearn import cluster, preprocessing as pre, linear_model as lm, cross_validation as cv, decomposition as decomp, metrics\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_SET = {\n",
    "    \"amazon\": \"data/amazon_cells_labelled.txt\",\n",
    "    \"imdb\": \"data/imdb_labelled.txt\",\n",
    "    \"yelp\": \"data/yelp_labelled.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A. Parse data sets\n",
    "amazon = pd.read_csv(DATA_SET['amazon'], sep=\"\\t\", header=None, names=['Sentence', 'Label']).dropna()\n",
    "imdb = pd.read_csv(DATA_SET['imdb'], sep=\"\\t(?=[01])\", header=None, names=['Sentence', 'Label'], engine='python').dropna()\n",
    "yelp = pd.read_csv(DATA_SET['yelp'], sep=\"\\t\", header=None, names=['Sentence', 'Label']).dropna()\n",
    "\n",
    "parsed_data = dict(zip(DATA_SET.keys(), [amazon, imdb, yelp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_label_ratio (data_set):\n",
    "    label_0 = sum(data_set['Label'] == 0)\n",
    "    label_1 = sum(data_set['Label'] == 1)\n",
    "    return (label_0, label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMAZON\n",
      "Label 0:  500\n",
      "Label 1:  500 \n",
      "\n",
      "\n",
      "IMDB\n",
      "Label 0:  500\n",
      "Label 1:  500 \n",
      "\n",
      "\n",
      "YELP\n",
      "Label 0:  500\n",
      "Label 1:  500 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print ratio of different labels per data set\n",
    "for k, data in parsed_data.items():\n",
    "    label_0, label_1 = get_label_ratio(data)\n",
    "    print k.upper()\n",
    "    print \"Label 0: \", label_0\n",
    "    print \"Label 1: \", label_1, \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# B. Preprocessing\n",
    "def preprocess (data):    \n",
    "    stopwords = set([\"the\", \"and\", \"or\", \"a\"]) # add some more later!\n",
    "    for i in range(len(data)):\n",
    "        data[i] = re.sub(\"[^a-zA-Z]\", \" \", data[i])\n",
    "        data[i] = data[i].lower().strip()\n",
    "        temp = [word for word in data[i].split() if word not in stopwords]\n",
    "        data[i] = \" \".join(temp)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, data in parsed_data.items():\n",
    "    parsed_data[k]['Sentence'] = preprocess(data['Sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# C. Split training and testing data\n",
    "def split_data (data):\n",
    "    zeros = data.loc[data['Label'] == 0]\n",
    "    ones = data.loc[data['Label'] == 1]\n",
    "    train, test = pd.concat([zeros[:400], ones[:400]]), pd.concat([zeros[400:], ones[400:]])\n",
    "    return (train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dict, test_dict = {}, {}\n",
    "for k, data in parsed_data.items():\n",
    "    train_dict[k], test_dict[k] = split_data(data)\n",
    "    \n",
    "train = pd.concat(train_dict, ignore_index=True)\n",
    "test = pd.concat(test_dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# D. Bag of words\n",
    "def get_bag (data):\n",
    "    bag = []\n",
    "    for sentence in data:\n",
    "        for word in sentence.split():\n",
    "            bag.append(word)\n",
    "    return np.unique(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag = get_bag(train['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N = 1 is same as str.split()\n",
    "def n_grams (sentence, n):\n",
    "    bag = []\n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)-n+1):\n",
    "        bag.append(\" \".join(words[i:i+n]))\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_vectors (bag, data, n=1):\n",
    "    features, labels = [], []\n",
    "    for i in range(len(data)):\n",
    "        f = []\n",
    "        s = n_grams(data['Sentence'][i], n)\n",
    "        l = data['Label'][i]\n",
    "        for word in bag:\n",
    "            f.append(s.count(word))\n",
    "        features.append(f)\n",
    "        labels.append(l)\n",
    "    return pd.DataFrame({\"feature\": features, \"label\": labels}, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features = get_feature_vectors(bag, train)\n",
    "test_features = get_feature_vectors(bag, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_rand_features (data):\n",
    "    plt.title(\"Random Feature Vector Freq.\")\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.ylabel(\"Frequencies\")\n",
    "    plt.hist(data, range=[0,1])\n",
    "    plt.xticks(range(0,2))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Training Sample Vector 1: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Random Training Sample Vector 2: \n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# print 2 random feature vectors from training set\n",
    "two_rand = random.sample(train_features['feature'].values, 2)\n",
    "print \"Random Training Sample Vector 1: \\n\", two_rand[0]\n",
    "print \"\\nRandom Training Sample Vector 2: \\n\", two_rand[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ac72d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhpg2EtSAwx7SWqAYS9JDTDsJakB/xfUD3HK5XQXcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11308ee50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fv in two_rand:\n",
    "    print_rand_features(fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# E. Postprocessing\n",
    "def post_process (data):\n",
    "    norm = []\n",
    "    for features in data:\n",
    "        mapped = map(float, features)\n",
    "        norm.append(pre.normalize(mapped, norm='l2').flatten())\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features_post = zip(post_process(train_features['feature'].values), train_features['label'])\n",
    "test_features_post = zip(post_process(test_features['feature'].values), test_features['label'])\n",
    "\n",
    "train_df = pd.DataFrame(train_features_post, columns=[\"feature\", \"label\"])\n",
    "test_df = pd.DataFrame(test_features_post, columns=[\"feature\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class KMeans:   \n",
    "    \n",
    "    def __init__(self, k_clusters = 2, max_iterations = 1000):\n",
    "        self.k_clusters = k_clusters\n",
    "        self.max_iterations = max_iterations\n",
    "        return\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "        centroids = self.get_initial_centroids(X)\n",
    "        old_centroids = []\n",
    "        \n",
    "        iteration = 0\n",
    "        while not np.array_equal(centroids, old_centroids) and iteration < self.max_iterations:\n",
    "            old_centroids = centroids.copy() # must copy list, not assign\n",
    "            # cluster points to nearest centroid\n",
    "            clusters, labels = self.clusters(centroids)\n",
    "            # update centroid\n",
    "            centroids = self.update_centroids(centroids, clusters)\n",
    "            iteration += 1            \n",
    "        return centroids, clusters, labels\n",
    "\n",
    "    def get_initial_centroids(self, X):\n",
    "        centroids = []\n",
    "        for i in range(0, self.k_clusters):\n",
    "            centroids.append(X['feature'][np.random.randint(0, len(X))])\n",
    "        return np.array(centroids)\n",
    "    \n",
    "    # creates clusters of points nearest to centroids\n",
    "    def clusters (self, centroids):\n",
    "        clusters = [[] for i in range(self.k_clusters)]\n",
    "        labels = [[] for i in range(self.k_clusters)]\n",
    "        for idx, x in self.X.iterrows():\n",
    "                min_dist = sys.maxint\n",
    "                kth_idx = -1\n",
    "                for idx2, centroid in enumerate(centroids):\n",
    "                    dist = spatial.distance.euclidean(x['feature'], centroid)\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        kth_idx = idx2\n",
    "                clusters[kth_idx].append(x['feature'])\n",
    "                labels[kth_idx].append(x['label'])\n",
    "        return clusters, labels\n",
    "\n",
    "    def update_centroids(self, centroids, clusters):\n",
    "        for idx, cluster in enumerate(clusters):\n",
    "            if cluster == []:\n",
    "                raise Exception('Empty cluster, try different centroid initialization')\n",
    "            centroids[idx] = np.array(cluster).sum(axis=0) / float(len(cluster))\n",
    "        return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cents, clusts, labs = KMeans(k_clusters = 2, max_iterations = 300).fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cent_freq (data):\n",
    "    plt.hist(data)\n",
    "    plt.title(\"Centroids Frequency\")\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(\"Values\")\n",
    "    plt.ylabel(\"Log Frequency\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10776a250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ac4ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c in cents:\n",
    "    plot_cent_freq(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid 0:\n",
      "[  1.35537475e-04   8.29994137e-05   0.00000000e+00 ...,   0.00000000e+00\n",
      "   0.00000000e+00   1.11916387e-04]\n",
      "Centroid 1:\n",
      "[ 0.          0.          0.00047617 ...,  0.00076356  0.00037514  0.        ]\n"
     ]
    }
   ],
   "source": [
    "for idx, cent in enumerate(cents):\n",
    "    print \"Centroid {0}:\\n{1}\".format(idx, cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in cluster 0: 1905\n",
      "Accuracy (Purity) of cluster 0 with label 0: 0.518635170604\n",
      "Number of elements in cluster 1: 495\n",
      "Accuracy (Purity) of cluster 1 with label 1: 0.571717171717\n"
     ]
    }
   ],
   "source": [
    "# accuracy was calculated using the 'purity' method, not NMI or RI\n",
    "def get_km_accuracy(label_set):\n",
    "    for idx, labels in enumerate(label_set):\n",
    "        counts = np.bincount(labels)\n",
    "        cluster_label = np.argmax(counts)\n",
    "        print \"Number of elements in cluster {0}: {1}\".format(idx, len(labels))\n",
    "        print \"Accuracy (Purity) of cluster {0} with label {1}: {2}\".format(idx, cluster_label, (labels == cluster_label).sum() / float(len(labels)))\n",
    "    return\n",
    "\n",
    "get_km_accuracy(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# G. Logistic Regression\n",
    "def logistic_regression (x_train, y_train, x_test, y_test, bag):\n",
    "    # Fit model\n",
    "    lr = lm.LogisticRegression(random_state=1).fit(x_train, y_train)\n",
    "\n",
    "    # Cross validation\n",
    "    scores = cv.cross_val_score(lr, x_train, y_train, cv=15)\n",
    "    print \"Cross validation: \", scores.mean()\n",
    "\n",
    "    # Prediction and scoring\n",
    "    predictions = lr.predict(x_test)\n",
    "    accuracy = (predictions == y_test).sum() / float(len(y_test))\n",
    "    print \"Prediction accuracy: \", accuracy\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print \"CONFUSION MATRIX:\"\n",
    "    print metrics.confusion_matrix(y_test, predictions)\n",
    "    \n",
    "    # most important weights/words\n",
    "    weights = [(idx, val) for idx, val in enumerate(lr.coef_[0])]\n",
    "    weights.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    num_important_words = 10\n",
    "    important_positive, important_negative = [], []\n",
    "    for i in range(num_important_words):\n",
    "        important_positive.append(bag[weights[i][0]])\n",
    "        important_negative.append(bag[weights[len(weights) - i - 1][0]])\n",
    "\n",
    "    print \"Top 10 Positive Important Words:\\n\", important_positive\n",
    "    print \"Top 10 Negative Important Words:\\n\", important_negative\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation:  0.796666666667\n",
      "Prediction accuracy:  0.821666666667\n",
      "CONFUSION MATRIX:\n",
      "[[257  43]\n",
      " [ 64 236]]\n",
      "Top 10 Positive Important Words:\n",
      "['great', 'good', 'love', 'excellent', 'nice', 'best', 'delicious', 'works', 'amazing', 'loved']\n",
      "Top 10 Negative Important Words:\n",
      "['not', 'bad', 'poor', 't', 'worst', 'terrible', 'awful', 'no', 'disappointing', 'horrible']\n"
     ]
    }
   ],
   "source": [
    "# G. Logistic Regression\n",
    "x_train = train_df['feature'].values.tolist()\n",
    "x_test = test_df['feature'].values.tolist()\n",
    "y_train = train_df['label']\n",
    "y_test = test_df['label']\n",
    "logistic_regression(x_train, y_train, x_test, y_test, bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create bag of bi-grams (n=2)\n",
    "bi_grams = np.unique(np.concatenate([n_grams(sentence, 2) for sentence in train['Sentence']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect feature vectors for each sentence in data\n",
    "bg_train_features = get_feature_vectors(bi_grams, train, 2)\n",
    "bg_test_features = get_feature_vectors(bi_grams, test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# N-gram post processing\n",
    "bg_train_features_post = zip(post_process(bg_train_features['feature'].values), bg_train_features['label'])\n",
    "bg_test_features_post = zip(post_process(bg_test_features['feature'].values), bg_test_features['label'])\n",
    "\n",
    "bg_train_df = pd.DataFrame(bg_train_features_post, columns=[\"feature\", \"label\"])\n",
    "bg_test_df = pd.DataFrame(bg_test_features_post, columns=[\"feature\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation:  0.702083333333\n",
      "Prediction accuracy:  0.698333333333\n",
      "CONFUSION MATRIX:\n",
      "[[194 106]\n",
      " [ 75 225]]\n",
      "Top 10 Positive Important Words:\n",
      "['very good', 'works great', 'is great', 'i love', 'is good', 'love this', 'great phone', 'is very', 'an excellent', 'highly recommend']\n",
      "Top 10 Negative Important Words:\n",
      "['didn t', 'don t', 'would not', 'do not', 'not good', 'piece of', 'very disappointed', 'doesn t', 'was terrible', 'waste of']\n"
     ]
    }
   ],
   "source": [
    "# Logistic regressin on bigram data\n",
    "bg_x_train = bg_train_df['feature'].values.tolist()\n",
    "bg_x_test = bg_test_df['feature'].values.tolist()\n",
    "bg_y_train = bg_train_df['label']\n",
    "bg_y_test = bg_test_df['label']\n",
    "logistic_regression(bg_x_train, bg_y_train, bg_x_test, bg_y_test, bi_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I. PCA\n",
    "def PCA(features, dimension):\n",
    "    features -= np.array(features).mean(axis=0)\n",
    "    u, s, v = np.linalg.svd(np.asmatrix(features))\n",
    "    return features.dot(np.array(v[:dimension]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dimensions = [10, 50, 100]\n",
    "train_dfs_truncated = {}\n",
    "test_dfs_truncated = {}\n",
    "for dim in dimensions:\n",
    "    train_dfs_truncated[dim] = pd.DataFrame(zip(PCA(x_train, dim), train_features['label']), columns=[\"feature\", \"label\"])\n",
    "    test_dfs_truncated[dim] = pd.DataFrame(zip(PCA(x_test, dim), test_features['label']), columns=[\"feature\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means for features of dimension:  10\n",
      "Centroid 0:\n",
      "[-0.1851601  -0.17807554  0.10163721  0.07300607 -0.02627294  0.06486828\n",
      "  0.00786388  0.02777045 -0.00242368 -0.00179958]\n",
      "Centroid 1:\n",
      "[ 0.04762368  0.04580151 -0.02614137 -0.01877736  0.00675747 -0.0166843\n",
      " -0.00202261 -0.00714264  0.00062338  0.00046286]\n",
      "Number of elements in cluster 0: 491\n",
      "Accuracy (Purity) of cluster 0 with label 1: 0.572301425662\n",
      "Number of elements in cluster 1: 1909\n",
      "Accuracy (Purity) of cluster 1 with label 0: 0.518596123625\n",
      "\n",
      "\n",
      "K-Means for features of dimension:  100\n",
      "Centroid 0:\n",
      "[ -1.37741685e-01   6.28544604e-02  -7.28995102e-02  -5.05266749e-02\n",
      "  -1.83595332e-01  -2.36365851e-01   6.70830996e-02   2.84047926e-01\n",
      "   9.57525140e-02  -9.24161622e-02   2.06430771e-02  -2.05945418e-02\n",
      "  -5.71633816e-03   8.01779871e-02   5.90865284e-04   1.23237066e-03\n",
      "  -1.93315134e-02  -9.14819594e-03  -1.98665298e-02  -3.18198806e-03\n",
      "   3.77676607e-03   7.16813785e-03   2.34002542e-03  -1.29081609e-02\n",
      "  -4.92258147e-03   8.33988412e-03  -2.16267746e-03  -1.36272774e-02\n",
      "   2.79277970e-03  -6.61083102e-03  -7.95445204e-03  -1.98434288e-03\n",
      "  -1.28044791e-03  -3.18445272e-03  -2.45493127e-04   3.28716930e-03\n",
      "  -3.92442998e-03   9.55811233e-04   4.00132567e-04  -2.03624907e-03\n",
      "   3.46773144e-03  -2.17198033e-03   8.03565567e-03  -1.00384926e-03\n",
      "   3.12621662e-03   2.19807934e-03   3.02335804e-03   1.86478313e-03\n",
      "  -1.77951970e-03   4.28317338e-05   2.92778965e-03   5.72826219e-04\n",
      "  -1.34634957e-03  -2.23874343e-04   1.40299853e-03   1.42439742e-03\n",
      "  -2.61880732e-03  -1.46649550e-03   2.79007177e-03  -2.59045932e-03\n",
      "   1.79607698e-03   1.02086266e-02   3.70128248e-03   5.82517114e-04\n",
      "  -7.01168482e-04   2.91979662e-03   3.82196030e-03   1.84825012e-03\n",
      "   2.28756920e-03   7.59129427e-04  -5.16704148e-04   8.96668889e-04\n",
      "  -7.23307809e-04  -8.10881826e-04   5.14616209e-04  -1.82194652e-03\n",
      "  -6.06672246e-04   1.23500480e-03   1.81612891e-03  -1.35539010e-03\n",
      "  -2.34938084e-03  -1.76349963e-04  -6.61613814e-05   7.97573229e-04\n",
      "  -8.53940995e-05  -1.43569364e-03   1.64622337e-03  -7.08797984e-05\n",
      "  -1.97647803e-03  -1.53935665e-04   1.21860927e-03  -9.69600616e-04\n",
      "   2.24742281e-04   1.33141812e-03   1.08356492e-03  -1.32049017e-03\n",
      "  -2.36968580e-04   1.48990858e-03  -1.64177486e-03   1.39784092e-03]\n",
      "Centroid 1:\n",
      "[  7.50438005e-03  -3.42440821e-03   3.97167806e-03   2.75277139e-03\n",
      "   1.00025576e-02   1.28775771e-02  -3.65479101e-03  -1.54753703e-02\n",
      "  -5.21674505e-03   5.03497544e-03  -1.12466677e-03   1.12202249e-03\n",
      "   3.11434944e-04  -4.36822074e-03  -3.21912545e-05  -6.71414594e-05\n",
      "   1.05321075e-03   4.98407863e-04   1.08235927e-03   1.73359631e-04\n",
      "  -2.05764056e-04  -3.90531236e-04  -1.27488204e-04   7.03256572e-04\n",
      "   2.68189852e-04  -4.54369785e-04   1.17826013e-04   7.42435146e-04\n",
      "  -1.52154957e-04   3.60168298e-04   4.33370849e-04   1.08110069e-04\n",
      "   6.97607825e-05   1.73493909e-04   1.33748452e-05  -1.79090067e-04\n",
      "   2.13809015e-04  -5.20740742e-05  -2.17998411e-05   1.10937998e-04\n",
      "  -1.88927372e-04   1.18332848e-04  -4.37794948e-04   5.46912600e-05\n",
      "  -1.70321116e-04  -1.19754762e-04  -1.64717222e-04  -1.01596269e-04\n",
      "   9.69509855e-05  -2.33353910e-06  -1.59510508e-04  -3.12084583e-05\n",
      "   7.33512068e-05   1.21970205e-05  -7.64375299e-05  -7.76033742e-05\n",
      "   1.42676673e-04   7.98969426e-05  -1.52007425e-04   1.41132230e-04\n",
      "  -9.78530518e-05  -5.56181763e-04  -2.01651594e-04  -3.17364333e-05\n",
      "   3.82007433e-05  -1.59075036e-04  -2.08226308e-04  -1.00695525e-04\n",
      "  -1.24630308e-04  -4.13585452e-05   2.81508411e-05  -4.88519078e-05\n",
      "   3.94069281e-05   4.41780959e-05  -2.80370869e-05   9.92624643e-05\n",
      "   3.30524422e-05  -6.72849717e-05  -9.89455116e-05   7.38437487e-05\n",
      "   1.27997902e-04   9.60781870e-06   3.60457438e-06  -4.34530230e-05\n",
      "   4.65240261e-06   7.82188097e-05  -8.96887952e-05   3.86164104e-06\n",
      "   1.07681580e-04   8.38665313e-06  -6.63917177e-05   5.28253411e-05\n",
      "  -1.22443071e-05  -7.25377181e-05  -5.90342926e-05   7.19423465e-05\n",
      "   1.29104147e-05  -8.11725237e-05   8.94464337e-05  -7.61565354e-05]\n",
      "Number of elements in cluster 0: 124\n",
      "Accuracy (Purity) of cluster 0 with label 1: 0.975806451613\n",
      "Number of elements in cluster 1: 2276\n",
      "Accuracy (Purity) of cluster 1 with label 0: 0.525922671353\n",
      "\n",
      "\n",
      "K-Means for features of dimension:  50\n",
      "Centroid 0:\n",
      "[ -1.83998664e-01  -1.77438903e-01   1.00746397e-01   7.24088210e-02\n",
      "  -2.60919430e-02   6.51293823e-02   7.29795998e-03   2.74547031e-02\n",
      "  -2.96593547e-03  -1.38225121e-03  -2.67285024e-03  -8.73078882e-04\n",
      "  -7.05582407e-03   1.00040785e-02   6.42918639e-03   1.27401144e-03\n",
      "  -7.20558087e-03   1.62098624e-03  -2.67451958e-04   1.47730613e-03\n",
      "   4.88261275e-04  -6.07077677e-04   3.72253719e-04  -4.97661732e-04\n",
      "   3.29690585e-03   1.71044255e-03   2.02852076e-03  -2.81702668e-03\n",
      "   1.26997814e-03   1.29009889e-03  -3.16315004e-03  -1.44138728e-04\n",
      "   2.27293820e-04  -1.04990333e-03  -1.64735302e-03  -5.76086992e-04\n",
      "   7.09573179e-04  -2.08933962e-03  -7.33542642e-04  -7.26631235e-04\n",
      "  -1.60641869e-03   1.59375106e-03   1.09747027e-03  -6.26573155e-04\n",
      "  -3.99192250e-04   2.07304723e-04  -7.31929703e-04  -3.17998752e-04\n",
      "   7.63862285e-04  -1.08802752e-03]\n",
      "Centroid 1:\n",
      "[  4.78106765e-02   4.61061715e-02  -2.61781977e-02  -1.88148905e-02\n",
      "   6.77979623e-03  -1.69233828e-02  -1.89632031e-03  -7.13389922e-03\n",
      "   7.70676145e-04   3.59167636e-04   6.94520141e-04   2.26863017e-04\n",
      "   1.83340310e-03  -2.59948495e-03  -1.67057599e-03  -3.31042343e-04\n",
      "   1.87231629e-03  -4.21201148e-04   6.94953905e-05  -3.83866946e-04\n",
      "  -1.26871040e-04   1.57744593e-04  -9.67273443e-05   1.29313678e-04\n",
      "  -8.56676325e-04  -4.44445702e-04  -5.27095946e-04   7.31983311e-04\n",
      "  -3.29994319e-04  -3.35222546e-04   8.21920877e-04   3.74533704e-05\n",
      "  -5.90605989e-05   2.72809527e-04   4.28052360e-04   1.49691896e-04\n",
      "  -1.84377283e-04   5.42899272e-04   1.90605568e-04   1.88809691e-04\n",
      "   4.17415880e-04  -4.14124290e-04  -2.85169440e-04   1.62810347e-04\n",
      "   1.03727120e-04  -5.38665815e-05   1.90186458e-04   8.26295970e-05\n",
      "  -1.98483901e-04   2.82715813e-04]\n",
      "Number of elements in cluster 0: 495\n",
      "Accuracy (Purity) of cluster 0 with label 1: 0.569696969697\n",
      "Number of elements in cluster 1: 1905\n",
      "Accuracy (Purity) of cluster 1 with label 0: 0.51811023622\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dim in train_dfs_truncated:\n",
    "    cents_post_pca, clusts_post_pca, labs_post_pca = KMeans(k_clusters = 2, max_iterations = 300).fit(train_dfs_truncated[dim])\n",
    "    print \"K-Means for features of dimension: \", dim\n",
    "    for idx, cent in enumerate(cents_post_pca):\n",
    "        print \"Centroid {0}:\\n{1}\".format(idx, cent)\n",
    "    get_km_accuracy(labs_post_pca)\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression for features of dimension:  10\n",
      "Cross validation:  0.618333333333\n",
      "Prediction accuracy:  0.521666666667\n",
      "Top 10 Positive Important Words:\n",
      "['abroad', 'above', 'about', 'ability', 'abandoned', 'abhor', 'absolute', 'aailiyah', 'able', 'abound']\n",
      "Top 10 Negative Important Words:\n",
      "['abound', 'able', 'aailiyah', 'absolute', 'abhor', 'abandoned', 'ability', 'about', 'above', 'abroad']\n",
      "Logistic Regression for features of dimension:  100\n",
      "Cross validation:  0.7425\n",
      "Prediction accuracy:  0.516666666667\n",
      "Top 10 Positive Important Words:\n",
      "['abroad', 'absolutely', 'above', 'activated', 'absolutel', 'accountant', 'acknowledged', 'ache', 'addition', 'absolutley']\n",
      "Top 10 Negative Important Words:\n",
      "['adorable', 'aired', 'abound', 'agreed', 'able', 'achievement', 'academy', 'advise', 'admiration', 'admitted']\n",
      "Logistic Regression for features of dimension:  50\n",
      "Cross validation:  0.688333333333\n",
      "Prediction accuracy:  0.518333333333\n",
      "Top 10 Positive Important Words:\n",
      "['abroad', 'absolutely', 'above', 'activated', 'absolutel', 'accountant', 'ache', 'acknowledged', 'absolutley', 'accidentally']\n",
      "Top 10 Negative Important Words:\n",
      "['abound', 'able', 'achievement', 'academy', 'actor', 'accurately', 'abstruse', 'aailiyah', 'access', 'acceptable']\n"
     ]
    }
   ],
   "source": [
    "for dim in train_dfs_truncated:\n",
    "    print \"Logistic Regression for features of dimension: \", dim\n",
    "    \n",
    "    x_train = train_dfs_truncated[dim]['feature'].values.tolist()\n",
    "    x_test = test_dfs_truncated[dim]['feature'].values.tolist()\n",
    "\n",
    "    y_train = train_dfs_truncated[dim]['label']\n",
    "    y_test = test_dfs_truncated[dim]['label']\n",
    "\n",
    "    # Fit model\n",
    "    lr_truncated = lm.LogisticRegression(random_state=1).fit(x_train, y_train)\n",
    "\n",
    "    # Cross validation\n",
    "    scores = cv.cross_val_score(lr_truncated, x_train, y_train, cv=15)\n",
    "    print \"Cross validation: \", scores.mean()\n",
    "\n",
    "    # Prediction and scoring\n",
    "    predictions = lr_truncated.predict(x_test)\n",
    "    accuracy = (predictions == y_test).sum() / float(len(y_test))\n",
    "    print \"Prediction accuracy: \", accuracy\n",
    "\n",
    "    # most important weights/words\n",
    "    weights = [(idx, val) for idx, val in enumerate(lr_truncated.coef_[0])]\n",
    "    weights.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    num_important_words = 10\n",
    "    important_positive, important_negative = [], []\n",
    "    for i in range(num_important_words):\n",
    "        important_positive.append(bag[weights[i][0]])\n",
    "        important_negative.append(bag[weights[len(weights) - i - 1][0]])\n",
    "\n",
    "    print \"Top 10 Positive Important Words:\\n\", important_positive\n",
    "    print \"Top 10 Negative Important Words:\\n\", important_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation:  0.618333333333\n",
      "Prediction accuracy:  0.521666666667\n",
      "CONFUSION MATRIX:\n",
      "[[154 146]\n",
      " [141 159]]\n",
      "Top 10 Positive Important Words:\n",
      "['abroad', 'above', 'about', 'ability', 'abandoned', 'abhor', 'absolute', 'aailiyah', 'able', 'abound']\n",
      "Top 10 Negative Important Words:\n",
      "['abound', 'able', 'aailiyah', 'absolute', 'abhor', 'abandoned', 'ability', 'about', 'above', 'abroad']\n",
      "\n",
      "\n",
      "\n",
      "Cross validation:  0.7425\n",
      "Prediction accuracy:  0.516666666667\n",
      "CONFUSION MATRIX:\n",
      "[[141 159]\n",
      " [131 169]]\n",
      "Top 10 Positive Important Words:\n",
      "['abroad', 'absolutely', 'above', 'activated', 'absolutel', 'accountant', 'acknowledged', 'ache', 'addition', 'absolutley']\n",
      "Top 10 Negative Important Words:\n",
      "['adorable', 'aired', 'abound', 'agreed', 'able', 'achievement', 'academy', 'advise', 'admiration', 'admitted']\n",
      "\n",
      "\n",
      "\n",
      "Cross validation:  0.688333333333\n",
      "Prediction accuracy:  0.518333333333\n",
      "CONFUSION MATRIX:\n",
      "[[147 153]\n",
      " [136 164]]\n",
      "Top 10 Positive Important Words:\n",
      "['abroad', 'absolutely', 'above', 'activated', 'absolutel', 'accountant', 'ache', 'acknowledged', 'absolutley', 'accidentally']\n",
      "Top 10 Negative Important Words:\n",
      "['abound', 'able', 'achievement', 'academy', 'actor', 'accurately', 'abstruse', 'aailiyah', 'access', 'acceptable']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dim in train_dfs_truncated:\n",
    "    x_train = train_dfs_truncated[dim]['feature'].values.tolist()\n",
    "    x_test = test_dfs_truncated[dim]['feature'].values.tolist()\n",
    "    y_train = train_dfs_truncated[dim]['label']\n",
    "    y_test = test_dfs_truncated[dim]['label']\n",
    "    \n",
    "    logistic_regression(x_train, y_train, x_test, y_test, bag)\n",
    "    print \"\\n\\n\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
